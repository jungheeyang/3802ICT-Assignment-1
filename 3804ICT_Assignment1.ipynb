{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3802ICT Assignment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align:right\">Junghee Yang (Kat) <br>\n",
    "Regnier Avice<br>\n",
    "Yunpeng Huang (Steven)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project title:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A brief description of the problem/question\n",
    "<p>Amsterdam is the capital city of Netherland with a population of 870,000 with 17 million tourists every year. Many tourists these days are staying at Airbnb hosted by homeowners. This dataset is from insiderairbnb.com which contains descriptions of Airbnb listings on 6th of December 2018 in Amsterdam. The dataset includes the name of the listing, number of reviews, locations, etc. </p>\n",
    "\n",
    "<p>This projects are consist of these problems/questions:</p>\n",
    " \n",
    "\n",
    "<ul>\n",
    "    <li><b>Classification and label prediction -</b> Can prices be predicted by the size of property and reviews?</li>\n",
    "    <li><b>Association and Correlation - </b></li>\n",
    "    <li><b>Clustering </b> - Do patterns in listening attributes correspond with the geographical location of the listenings?</li>\n",
    "</ul>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset description\n",
    "<p>The dataset contains Airbnb listings in Amsterdam on 6th December 2018 and it was retrieved from Kaggle which was downloaded from insideairbnb.com. It contains details of Airbnb listings such as prices, reviews, size of the place, etc. with 96 attributes with 20,030 data samples. </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algorithms/techniques for different learning tasks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### - Classification and label prediction\n",
    "<b>Binary Classification using K-Nearest Neighbours</b>: Binary classification is one of the  Supervised Learning methods. It is classifying the elements to one or the other by measuring a series of attributes. \n",
    "\n",
    "K-nearest neighbours (KNN) algorithm is a type of supervised ML algorithm which can be used for both classifications as well as predictive regression problems. K-nearest neighbours (KNN) algorithm uses ‘feature similarity’ to predict the values of new datapoints which further means that the new data point will be assigned a value based on how closely it matches the points in the training set. <p style=\"font-size:60%;\">KNN Algorithm - Finding Nearest Neighbors - Tutorialspoint. https://www.tutorialspoint.com/machine_learning_with_python/machine_learning_with_python_knn_algorithm_finding_nearest_neighbors.htm<p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association and Correlation\n",
    "<b>Alg:</b> Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "<b>K-Means (Lloyd’s Algorithm):</b> K-Means clustering is based on the idea to generate k clusters and assign each point to the cluster with the nearest mean-point. The optimal approach is NP-Hard with exponential time complexity. The Lloyd’s Algorithm is a heuristic approach to approximate the optimal result which in practice should run in linear time complexity <font color=\"red\">reference</font>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measurements to evaluate the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression\n",
    "#### Mean squared error\n",
    "\n",
    "Mean squared error is the average squared differene between the estiation and the reuslts. It is always positive value and the closer to zero, more accurate the estimation. MSE is computed as\n",
    "\n",
    "$\n",
    "{\\large\n",
    "\\begin{align}\n",
    "MSE = \\frac{1}{n}\\sum (Y_i - \\hat{Y}_i)^2\n",
    "\\end{align}\n",
    "}%\n",
    "$\n",
    "\n",
    ", where $\n",
    "{\n",
    "\\begin{align}\n",
    "Y\n",
    "\\end{align}\n",
    "}%\n",
    "$ is the tector of observed values of the variable being predicted, with $\n",
    "{\n",
    "\\begin{align}\n",
    "\\hat{Y}\n",
    "\\end{align}\n",
    "}%\n",
    "$ being the predicted value. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Association and Correlation\n",
    "Some metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clustering\n",
    "\n",
    "To evaluate the effectiveness of clusters the Intracluster and Intercluster distance is measured. Effective clustering minimizes the Intracluster distance while maximizing the Intercluster distance.\n",
    "\n",
    "For this project two popular methods are used. The Dunn Index and the Silhouette analysis.\n",
    "\n",
    "#### Dunn Index\n",
    "\n",
    "The goal is to maximize the value of the Dunn Index. A high Dunn Index indicates large inter cluster distance and low intra cluster distance. \n",
    "\n",
    "$\n",
    "{\\large\n",
    "\\begin{align}\n",
    "DunnIndex = \\frac{min(d(InterCluster))}{max (d(IntraCluster))} \n",
    "\\end{align}\n",
    "}%\n",
    "$\n",
    "\n",
    "\n",
    "where the inter cluster distance is the maximum distance between two points of two clusters\n",
    "\n",
    "$\n",
    "{\\large\n",
    "\\begin{align}\n",
    "d(InterCluster) = max(C_{a_i}, C_{b_j})\n",
    "\\end{align}\n",
    "}%\n",
    "$\n",
    "\n",
    "\n",
    "and the intra cluster distance is maximum distance between two points of the same cluster\n",
    "\n",
    "$\n",
    "{\\large\n",
    "\\begin{align}\n",
    "d(InterCluster) = max(C_{a_i}, C_{a_j})\n",
    "\\end{align}\n",
    "}%\n",
    "$\n",
    "\n",
    "#### Silhouette analysis\n",
    "\n",
    "For each point the silhouette value will be caluclated which can have the range of [-1,1]. The goal is to maximize the silhouette value. Many negative values are an indication for to many or to few clusters. This value will be used to determine the right size of $k$.\n",
    "\n",
    "$\n",
    "{\\large\n",
    "\\begin{align}\n",
    "\\Delta s(i) = \\frac{b(i)-a(i)}{max (a(i),b(i)}\n",
    "\\end{align}\n",
    "}%\n",
    "$\n",
    "\n",
    "where $a(i)$ is the mean distance of the point $i$ to other points of the same cluster\n",
    "\n",
    "$\n",
    "{\\large\n",
    "\\begin{align}\n",
    "\\Delta a(i) = \\frac{\\Sigma  d(i,j)}{|C_i| -1}\n",
    "\\end{align}\n",
    "}%\n",
    "$\n",
    "\n",
    "and $b(i)$ is the minimum (In case of more than two clusters the smallest mean is taken) mean distance of the point $i$ to other points of the other cluster. \n",
    "$\n",
    "{\\large\n",
    "\\begin{align}\n",
    "\\Delta b(i) = min(\\frac{\\Sigma  d(i,j)}{|C_k|}) \\hspace{1cm}for \\hspace{0.5cm} k \\neq i\n",
    "\\end{align}\n",
    "}%\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries and dataset \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read dataset\n",
    "git_url = \"https://raw.githubusercontent.com/jungheeyang/3802ICT-Assignment-1/master/listings_details.csv\"\n",
    "col_list = ['host_response_rate', 'host_is_superhost', 'host_identity_verified', 'zipcode', \n",
    "            'property_type', 'room_type', 'accommodates', 'bathrooms', 'bedrooms', 'beds', \n",
    "            'price', 'weekly_price', 'monthly_price', 'security_deposit', 'number_of_reviews',\n",
    "            'review_scores_rating', 'latitude', 'longitude', 'is_location_exact']\n",
    "\n",
    "df = pd.read_csv(git_url, sep=',', usecols=col_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial preprocessing is conducted to convert the attribute data types into a consistent format before the data exploration is started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dollar_to_float(df):\n",
    "    df = df.replace('[\\$,]', '', regex=True).astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "def obj_to_bool(df):\n",
    "    df = df.replace('f', 'FALSE', regex=True).astype(bool)\n",
    "    df = df.replace('t', 'TRUE', regex=True).astype(bool)\n",
    "    return df\n",
    "\n",
    "\n",
    "def percent_to_float(df):\n",
    "    df = df.replace('%', '', regex=True).astype(float)\n",
    "    return df\n",
    "\n",
    "\n",
    "df.host_response_rate = percent_to_float(df.host_response_rate)\n",
    "\n",
    "df.price = dollar_to_float(df.price)\n",
    "df.security_deposit = dollar_to_float(df.security_deposit)\n",
    "df.weekly_price = dollar_to_float(df.weekly_price)\n",
    "df.monthly_price = dollar_to_float(df.monthly_price)\n",
    "df.security_deposit = dollar_to_float(df.security_deposit)\n",
    "\n",
    "df.host_is_superhost = obj_to_bool(df.host_is_superhost)\n",
    "df.host_identity_verified = obj_to_bool(df.host_identity_verified)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<ul>\n",
    "    <li style=\"font-size:16px\">Number of the data samples</li>\n",
    "    <ul>\n",
    "        <li style=\"list-style-type: square\">Total number of samples: 20,030</li>\n",
    "    </ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<ul>\n",
    "    <ul>\n",
    "        <li style=\"list-style-type: square\">Total number of NULL</li>\n",
    "    </ul>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<ul>\n",
    "    <li style=\"font-size:16px\">Types of attributes</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "<br>\n",
    "<ul>\n",
    "    <li style=\"font-size:16px\">statistical information of each attribute - Five number summery</li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New data frame for cleaned data\n",
    "dfc = df.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Drop unuseful column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.drop(['host_response_rate'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove unuseful records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove if beds, bedrooms, bathrooms, zipcode, review_scores_rating are missing\n",
    "dfc.dropna(subset=['beds', 'bedrooms', 'bathrooms', 'zipcode', 'review_scores_rating'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate missing weekly and monthly prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Standard weekly price is 7*price\n",
    "dfc['weekly_price'].fillna(dfc['price']*7, inplace=True)\n",
    "\n",
    "#Standard monthly price is 30*price\n",
    "dfc['monthly_price'].fillna(dfc['price']*30, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Replace empty security deposit with 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['security_deposit'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exclude property with listed price of 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc = dfc.loc[dfc['price'] > 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove outliers in price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc['z_score'] = np.abs(stats.zscore(dfc['price']))\n",
    "dfc = dfc[dfc.z_score < 3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Check data after pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# No NULL values \n",
    "dfc.isnull().sum(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(15,8))\n",
    "\n",
    "axs[0].boxplot(df['price'])\n",
    "axs[0].set_title('Price data')\n",
    "\n",
    "axs[1].boxplot(dfc['price'])\n",
    "axs[1].set_title('Cleaned Price data')\n",
    "\n",
    "fig.show"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfc.to_csv('listings_details_cleaned.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
